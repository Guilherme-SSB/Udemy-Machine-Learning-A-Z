{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_preprocessing.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"154Wi8A4iTYENMxRKeddT0aveCVCeciqS","authorship_tag":"ABX9TyOSeRDLv8/WYPPzNvvpNhh5"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dWkNQVP5otzP"},"source":["# Data Preprocessing "]},{"cell_type":"markdown","metadata":{"id":"5SLTWwQqov1f"},"source":["## Importing the libraries"]},{"cell_type":"code","metadata":{"id":"2c9nzBCRn8lU","executionInfo":{"status":"ok","timestamp":1616076549894,"user_tz":180,"elapsed":715,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}}},"source":["import numpy as np                # Work with arrays, machine learning models use arrays as inputs\r\n","import matplotlib.pyplot as plt   # Plotting\r\n","import pandas as pd               # Import dataset and create the matrix of features and dependent variable vector"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"li5q8tLUoxrY"},"source":["## Importing the dataset"]},{"cell_type":"code","metadata":{"id":"lVxhXKNwoyZV","executionInfo":{"status":"ok","timestamp":1616079783484,"user_tz":180,"elapsed":747,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}}},"source":["dataset = pd.read_csv('Data.csv') \r\n","X = dataset.iloc[:, :-1].values  # Matrix of features (Independent variable), x: numpy.ndarray\r\n","y = dataset.iloc[:, -1].values   # Dependent variable vector (what you want to predict), y: numpy.ndarray\r\n","\r\n","\r\n","# iloc[rows, columns]\r\n","# .values -> pandas.Series to numpy.ndarray"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"jk5vtGzfpjhy","executionInfo":{"status":"ok","timestamp":1616079786348,"user_tz":180,"elapsed":1501,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"1c0d44c5-8b8d-477d-f86d-05ab21029b79"},"source":["display(dataset)"],"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Country</th>\n","      <th>Age</th>\n","      <th>Salary</th>\n","      <th>Purchased</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>France</td>\n","      <td>44.0</td>\n","      <td>72000.0</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Spain</td>\n","      <td>27.0</td>\n","      <td>48000.0</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Germany</td>\n","      <td>30.0</td>\n","      <td>54000.0</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Spain</td>\n","      <td>38.0</td>\n","      <td>61000.0</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Germany</td>\n","      <td>40.0</td>\n","      <td>NaN</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>France</td>\n","      <td>35.0</td>\n","      <td>58000.0</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Spain</td>\n","      <td>NaN</td>\n","      <td>52000.0</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>France</td>\n","      <td>48.0</td>\n","      <td>79000.0</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Germany</td>\n","      <td>50.0</td>\n","      <td>83000.0</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>France</td>\n","      <td>37.0</td>\n","      <td>67000.0</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Country   Age   Salary Purchased\n","0   France  44.0  72000.0        No\n","1    Spain  27.0  48000.0       Yes\n","2  Germany  30.0  54000.0        No\n","3    Spain  38.0  61000.0        No\n","4  Germany  40.0      NaN       Yes\n","5   France  35.0  58000.0       Yes\n","6    Spain   NaN  52000.0        No\n","7   France  48.0  79000.0       Yes\n","8  Germany  50.0  83000.0        No\n","9   France  37.0  67000.0       Yes"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gBwoWrt7pHY-","executionInfo":{"status":"ok","timestamp":1616079787481,"user_tz":180,"elapsed":667,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"7da42717-dd69-4ac3-fa2a-68f20a98239f"},"source":["print(X)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 nan]\n"," ['France' 35.0 58000.0]\n"," ['Spain' nan 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ix98Vc6gpUDK","executionInfo":{"status":"ok","timestamp":1616079789363,"user_tz":180,"elapsed":705,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"f808d72a-ec66-4151-dc8d-d6869c676b2d"},"source":["print(y)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ssxaoQEjqWRi"},"source":["## Taking care of missing data\r\n","\r\n","1. Ignore the missing data and just delete it (Depents of the % of the missing data)\r\n","2. Replace the missing data by the {average, median, mean, most frequenty value} of all values of the same column"]},{"cell_type":"code","metadata":{"id":"HPlFLMe9u2zG","executionInfo":{"status":"ok","timestamp":1616079790884,"user_tz":180,"elapsed":984,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}}},"source":["from sklearn.impute import SimpleImputer\r\n","\r\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean')   # Create a Object of SimpleImputer class\r\n","imputer.fit(X[:, 1:3])                     # .fit expects numerical columns, so we pass only 'Age' and 'Salary' columns, [1:3]\r\n","X[:, 1:3] = imputer.transform(X[:, 1:3])   # .transform expects the columns of X where we want to replace the missing data\r\n","                                           # .transform returns a new numpy array with the new data, X[:, 1:3] = .transform\r\n","\r\n","\r\n","# missing_values=np.nan -> Defining np.nan as the missing values\r\n","# strategy='mean'       -> Substite np.nan by the strategy (mean)\r\n","# .fit                  -> connect the 'imputer' to the matrix of features\r\n","# .transform            -> actually will make the replacement"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mm6UQTmcyOZm","executionInfo":{"status":"ok","timestamp":1616079791729,"user_tz":180,"elapsed":562,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"f81842e8-f129-4f75-f6c7-6c149fc6493b"},"source":["print(X)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 63777.77777777778]\n"," ['France' 35.0 58000.0]\n"," ['Spain' 38.77777777777778 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6NlrRMkAqYdq"},"source":["## Enconding categorical data\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"8VFoLia7qabu"},"source":["### Enconding the Independent Variable (One-hot Encoder)\r\n","\r\n","We can't just say \"France = 1\", \"Spain = 2\", \"Germany = 3\". Our machine learning model will understand that it has an numerical order and worst, this order matters. WE DON'T WANT IT !!!\r\n"]},{"cell_type":"markdown","metadata":{"id":"w0mXb3Rf3Swx"},"source":["**One-hot Encoder:**\r\n","\r\n","Turn this Country column into three columns, because we have three different classes on Country column, and it will create a **binary vector** for each of this coutries. For example: \r\n","\r\n","France = [1 0 0] \r\n","\r\n","Spain = [0 1 0]\r\n","\r\n","Germany = [0 0 1]\r\n","\r\n","And now, there is no numerical order involved"]},{"cell_type":"code","metadata":{"id":"Xn57Vn38yhh2","executionInfo":{"status":"ok","timestamp":1616079794756,"user_tz":180,"elapsed":1025,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}}},"source":["from sklearn.compose import ColumnTransformer\r\n","from sklearn.preprocessing import OneHotEncoder\r\n","\r\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')   # Create a Object of ColumnTransformer class\r\n","X = np.array(ct.fit_transform(X))   # .fit_transform returns a new object\r\n","\r\n","\r\n","# transformers=[(kind of transformation, what kind of enconding(), [indexs of the columns we want to enconde[])]\r\n","# remainder='passthrough' -> we want to keep the columns that we are not encoding\r\n","# np.array() -> to force the output to be a numpy array"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCaTOWph26oj","executionInfo":{"status":"ok","timestamp":1616079795648,"user_tz":180,"elapsed":552,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"a3e3b571-7c2d-46ef-cfd4-c3c614b43fd9"},"source":["print(X)   # Dummie Variables"],"execution_count":49,"outputs":[{"output_type":"stream","text":["[[1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [0.0 1.0 0.0 30.0 54000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 35.0 58000.0]\n"," [0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nIvihAXJyjZx"},"source":["### Enconding the Dependent Variable\r\n","\r\n","On Purchased column, we will turn 'Yes' into '1' and 'No' into '0'"]},{"cell_type":"code","metadata":{"id":"X9Ryc92q3cfe","executionInfo":{"status":"ok","timestamp":1616079976230,"user_tz":180,"elapsed":1315,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}}},"source":["from sklearn.preprocessing import LabelEncoder\r\n","\r\n","le = LabelEncoder()   # Create a Object of LabelEncoder class\r\n","y = le.fit_transform(y)"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MLGdv2J333Yz","executionInfo":{"status":"ok","timestamp":1616079978823,"user_tz":180,"elapsed":838,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"bb07d601-b0e7-46c2-ab38-95e64b7d9ff9"},"source":["print(y)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["[0 1 0 0 1 1 0 1 0 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aaxi_ZHUozdT"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","metadata":{"id":"iJWY0OJqo0YG","executionInfo":{"status":"ok","timestamp":1616080857333,"user_tz":180,"elapsed":702,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}}},"source":["from sklearn.model_selection import train_test_split\r\n","\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4-xVzuo7U-J","executionInfo":{"status":"ok","timestamp":1616080912092,"user_tz":180,"elapsed":1097,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"b265275e-c70b-459e-8b5f-2bbc65a5f0fb"},"source":["print(X_train)"],"execution_count":61,"outputs":[{"output_type":"stream","text":["[[0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 35.0 58000.0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ad-RklIy7U53","executionInfo":{"status":"ok","timestamp":1616080911425,"user_tz":180,"elapsed":852,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"7af91f47-f569-40a2-87c5-714550af3fa5"},"source":["print(X_test)"],"execution_count":60,"outputs":[{"output_type":"stream","text":["[[0.0 1.0 0.0 30.0 54000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jOyKCmlG7U0p","executionInfo":{"status":"ok","timestamp":1616080914805,"user_tz":180,"elapsed":748,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"bd28f8e2-e779-4076-fb93-b32e26187fbf"},"source":["print(y_train)"],"execution_count":62,"outputs":[{"output_type":"stream","text":["[0 1 0 0 1 1 0 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HyVpj_F17UwF","executionInfo":{"status":"ok","timestamp":1616080910589,"user_tz":180,"elapsed":797,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"ef834593-919f-42e3-8ad9-c1711ed6b0bb"},"source":["print(y_test)"],"execution_count":58,"outputs":[{"output_type":"stream","text":["[0 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"voI-8Lqu45xe"},"source":["## Feature Scaling\r\n","\r\n","We do the Feature Scaling to prevents that one feature became for revalent than other. Feature Scaling = makes all features have the same \"weight\".\r\n","\r\n","\r\n","- AFTER splitting the dataset. \r\n","\r\n","That's because we don't want to show Test set to out machine learning model, it is suppose to be new data, new observations to ML model.\r\n","\r\n","- Do not apply to our Dummie Variable, it is already scalled\r\n","\r\n","- We don't need to apply Feature Scaling to all ML models.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"C3hhKqe99Ee2"},"source":["### Standardisation\r\n","\r\n","$$\r\n","\r\n","x_{stand} = \\frac{x-mean(x)}{sd(x)}\r\n","\r\n","$$\r\n","\r\n","Where, $sd$ is the Standard deviation\r\n","\r\n","Results: between -3 and +3\r\n","\r\n","It will work all the time, no restriction."]},{"cell_type":"markdown","metadata":{"id":"gj9UPkAM9Sgc"},"source":["### Normalisation\r\n","\r\n","$$\r\n","\r\n","x_{norm} = \\frac{x-min(x)}{max(x) - min(x)}\r\n","\r\n","$$\r\n","\r\n","Results: between 0 and +1\r\n","\r\n","It it used when you have a Normal Distribution to most your features"]},{"cell_type":"code","metadata":{"id":"6Z8Sn9qP-fru","executionInfo":{"status":"ok","timestamp":1616082012695,"user_tz":180,"elapsed":773,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}}},"source":["from sklearn.preprocessing import StandardScaler\r\n","\r\n","sc = StandardScaler()   # Create a Object of StandardScaler class\r\n","\r\n","X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])   # Only apply to 'Age' and 'Salary'\r\n","X_test[:, 3:] = sc.fit_transform(X_test[:, 3:])     # Only apply to 'Age' and 'Salary'"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rl_cwdAA-nVJ","executionInfo":{"status":"ok","timestamp":1616082014012,"user_tz":180,"elapsed":729,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"67e353ed-f02a-4906-d92d-657468eddf40"},"source":["print(X_train)"],"execution_count":66,"outputs":[{"output_type":"stream","text":["[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n"," [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n"," [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n"," [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n"," [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n"," [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n"," [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n"," [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0wXkNtv-oML","executionInfo":{"status":"ok","timestamp":1616082014442,"user_tz":180,"elapsed":629,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"64cf2624-ac07-4820-b979-0b7c6bbd8dfd"},"source":["print(X_test)"],"execution_count":67,"outputs":[{"output_type":"stream","text":["[[0.0 1.0 0.0 -1.0 -1.0]\n"," [1.0 0.0 0.0 1.0 1.0]]\n"],"name":"stdout"}]}]}